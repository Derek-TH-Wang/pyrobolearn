#!/usr/bin/env python
"""Define dynamic movement primitives (their canonical and transformation systems)

This file implements dynamic movement primitives for discrete and rhythmic movements.
"""


from abc import ABCMeta, abstractmethod
import numpy as np
import scipy.interpolate


__author__ = "Brian Delhaisse"
__copyright__ = "Copyright 2018, PyRoboLearn"
__credits__ = ["Brian Delhaisse"]
__license__ = "MIT"
__version__ = "1.0.0"
__maintainer__ = "Brian Delhaisse"
__email__ = "briandelhaisse@gmail.com"
__status__ = "Development"


# Canonical Systems #

class CS(object):
    r"""Canonical System.

    A canonical system (CS) drives a dynamic movement primitive (DMP) by providing a phase variable [1].
    The phase variable was introduced to avoid an explicit dependency with time in the DMP equations. Canonical
    systems can be categorized in two main categories:
    * discrete CS: used for discrete movements (such as reaching, pushing/pulling, hitting, etc)
    * rhythmic CS: used for rhythmic movements (such as walking, running, dribbling, sewing, flipping a pancake, etc)

    Each of these systems are described by differential equations which are solved using Euler's method.
    See their corresponding classes `DiscreteCS` and `RhythmicCS` for more information.

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
    """

    __metaclass__ = ABCMeta

    def __init__(self, dt=0.01, T=1.):
        """Initialize the canonical system.

        Args:
            dt (float): the time step used in Euler's method when solving the differential equation
                A very small step will lead to a better accuracy but will take more time.
        """
        # set variables
        self.dt = dt
        self.T = T
        self.timesteps = int(T / self.dt)
        # rescale integration step (same as np.linspace(0.,T.,timesteps) instead of np.arange(0,T,dt))
        self.dt = self.T / (self.timesteps - 1.)

        self.init_phase = 1.0
        self.s = 1.0

        # reset the phase variable
        self.reset()

    @abstractmethod
    def step(self, tau=1.0, error_coupling=1.0):
        """Perform a step using Euler's method. This needs to be implemented in the child classes."""
        raise NotImplementedError

    def reset(self):
        """Reset the phase variable"""
        self.s = self.init_phase
        return self.s

    def rollout(self, tau=1.0, error_coupling=1.0):
        """Generate phase variable in an open loop fashion.

        Args:
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            error_coupling (float): slow down if the error is > 1
        """
        timesteps = int(self.timesteps * tau)
        self.s_track = np.zeros(timesteps)

        # reset
        self.reset()

        # roll
        for t in range(timesteps):
            self.s_track[t] = self.s
            self.step(tau, error_coupling)

        return self.s_track


class DiscreteCS(CS):
    r"""Discrete Canonical System.

    The discrete canonical system drives the various DMPs by providing the phase variable at each time step, and is
    given by:

    .. math:: \tau \dot{s} = - \alpha_s s

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the movement, :math:`s` is the phase
    variable that drives the DMP, and :math:`\alpha_s` is a predefined constant.
    This differential equation is solved using Euler's method.

    This version is used for discrete movements, where :math:`s` starts from 1 and converge to 0 as time progresses.
    The phase variable was introduced to avoid an explicit dependency of time in the DMP equations.

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
    """

    def __init__(self, alpha_s=1, dt=0.01):
        super(DiscreteCS, self).__init__(dt=dt, T=1.0)
        self.alpha_s = alpha_s

    def reset(self):
        """Reset the phase variable"""
        self.s = self.init_phase
        return self.s

    def step(self, tau=1.0, error_coupling=1.0):
        """Generate phase value for discrete movements.

        The phase variable :math:`s` is generated by solving :math:`\tau \dot{s} = - \alpha_s s` using Euler's method.
        This phase decays from 1 to 0.

        Args:
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            error_coupling (float): slow down if the error is > 1

        Returns:
            float: phase value
        """
        s = self.s
        self.s += (-self.alpha_s/tau * self.s * error_coupling) * self.dt
        # return self.s
        return s


class RhythmicCS(CS):
    r"""Rhythmic Canonical System.

    The rhythmic canonical system drives the various DMPs by providing a phase variable that is periodic [1]. It is
    used for rhythmic movements (such as walking, dribbling, sewing, etc.) and is given by:

    .. math:: \tau \dot{s} = 1

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the movement, :math:`s` is the phase
    variable that drives the DMP. This differential equation is solved using Euler's method.

    Rhythmic canonical systems can also be coupled with each other as done in [2] to synchronize various DMPs.

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
        [2] "A Framework for Learning Biped Locomotion with Dynamical Movement Primitives", Nakanishi et al., 2004
    """

    def __init__(self, dt=0.01):
        super(RhythmicCS, self).__init__(dt=dt, T=2*np.pi)
        self.init_phase = 0.0

    def reset(self):
        """Reset the phase variable"""
        self.s = self.init_phase
        return self.s

    def step(self, tau=1.0, error_coupling=1.0):
        r"""Generate phase value for rhythmic movements.

        The phase variable :math:`s` is generated by solving :math:`\tau \dot{s} = 1` using Euler's method.

        Args:
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            error_coupling (float): slow down if the error is > 1

        Returns:
            float: phase value
        """
        s = self.s
        self.s += (1./tau * error_coupling) * self.dt
        # return self.s
        return s


class RhythmicNetworkCS(CS):
    r"""Rhythmic Network CS.

    In this version, instead of having one canonical system that drives all the various DMPs, we have several
    canonical systems coupled with each other, and where each one of them is associated to a particular DMP.

    The evolution of the phase variable :math:`\phi` of the system :math:`i` is given by:

    .. math:: \dot{\phi}_i = \omega_i + \sum_j a_j w_{ij} \sin(\phi_j - \phi_i - \varphi_{ij})

    where :math:`\omega` is the desired angular velocity (desired frequency), :math:`w_{ij}` are the coupling weights,
    :math:`\varphi_{ij}` are the phase biases, and :math:`a_j` are the amplitudes of the other systems :math:`j`.
    This formulation is similar to Central Pattern Generators (CPGs), see [3].

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
        [2] "A Framework for Learning Biped Locomotion with Dynamical Movement Primitives", Nakanishi et al., 2004
        [3] "Central pattern generators for locomotion control in animals and robots: a review", Ijspeert, 2008
    """
    def __init__(self, dt=0.01):
        super(RhythmicNetworkCS, self).__init__(dt=dt)


# Basis Functions #

class BF(object):
    r"""Basis function used in the forcing terms
    """
    __metaclass__ = ABCMeta

    def __init__(self):
        pass

    @abstractmethod
    def compute(self, s):
        raise NotImplementedError

    # alias
    def __call__(self, s):
        return self.compute(s)


class EBF(BF):
    r"""Exponential basis function

    This basis function is given by the formula:

    .. math:: \psi(s) = \exp \left( - \frac{1}{2 \sigma^2} (s - c)^2 \right)

    where :math:`c` is the center, and :math:`\sigma` is the width of a normal distribution.

    This is often used for discrete DMPs.
    """
    def __init__(self, center=0, sigma=1., h=None):
        """Initialize basis function

        Args:
            center (float, np.ndarray): center of the distribution
            sigma (float, np.ndarray): width of the distribution
            h (float, np.ndarray): concentration/precision of the basis fct (h = 1/(2*\sigma^2)).
                                   if h is not provided, it will check sigma.
        """
        super(EBF, self).__init__()

        if isinstance(center, np.ndarray): pass

        self.c = center
        if h is None:
            self.h = 1. / (2*sigma**2) # measure the concentration
        else:
            self.h = h

    def compute(self, s):
        if isinstance(s, np.ndarray):
            s = s[:, None]
        return np.exp(-self.h * (s - self.c)**2)


class CBF(BF):
    r"""Circular basis function (aka von Mises basis function)

    This basis function is given by the formula:

    .. math:: \psi(s) = \exp \left( h (\cos(s - c) - 1) \right)

    where :math:`c` is the center, and :math:`h` is a measure of concentration.

    This is often used for rhythmic DMPs.
    """
    def __init__(self, center=0, h=1.):
        """Initialize basis function

        Args:
            center (float, np.ndarray): center of the basis fct
            h (float, np.ndarray): concentration/precision of the basis fct
        """
        super(CBF, self).__init__()
        self.c = center
        self.h = h

    def compute(self, s):
        if isinstance(s, np.ndarray):
            s = s[:, None]
        # return np.exp(self.h * np.cos(s - self.c) - 1)     # this is bad as it is not bounded as we increase the
                                                             # number of basis functions.
        return np.exp(self.h * np.cos(s - self.c) - self.h)


# FORCING TERMS #

class ForcingTerm(object):
    r"""Forcing term used in DMPs

    This basically computes the unscaled forcing term, i.e. a weighted sum of basis functions, which is given by:

    .. math:: f(s) = \frac{ sum_{i} \psi_i(s) w_i }{ \sum_i \psi_i(s) }

    where :math:`w` are the learnable weight parameters, and :math:`\psi` are the basis functions evaluated at the
    given input phase variable :math:`s`.
    """

    def __init__(self, weights, basis_functions):
        # check that the arguments have the same length
        self.w = weights
        self.psi = basis_functions

    @property
    def weights(self):
        return self.w

    @staticmethod
    def is_linear():
        return True

    @staticmethod
    def is_parametric():
        return True

    @staticmethod
    def is_recurrent():
        return False

    def compute(self, s):
        """Compute the forcing term

        Compute the value of the forcing term :math:`f(s)` at the given phase value :math:`s`.

        Args:
            s (float): phase value

        Returns:
            float: value of the forcing term at the given phase value
        """
        psi_track = self.psi(s)
        if len(psi_track.shape) == 1:
            return np.dot(psi_track, self.w) / np.sum(psi_track)
        return np.dot(psi_track, self.w) / np.sum(psi_track, axis=1)

    def weighted_basis(self, s):
        """Generate weighted basis

        Returns:
            np.array[T, M]: weighted basis
        """
        return self.psi(s) * self.w

    def normalized_weighted_basis(self, s):
        """Generate normalized weighted basis

        Args:
            s (float): phase value

        Returns:
            np.array[T,M]: normalized weighted basis
        """
        psi_track = self.psi(s)
        return ((psi_track * self.w).T / np.sum(psi_track, axis=1)).T

    # alias
    def __call__(self, s):
        return self.compute(s)

    def __str__(self):
        return self.__class__.__name__

    # To override in child classes
    def train(self, f_target):
        raise NotImplementedError

    # alias
    generate_weights = train


class DiscreteForcingTerm(ForcingTerm):
    r"""Discrete Forcing Term

    .. math:: f(s) = \frac{ sum_{i} \psi_i(s) w_i }{ \sum_i \psi_i(s) } s

    where :math:`w` are the learnable weight parameters, and :math:`\psi` are the basis functions evaluated at the
    given input phase variable :math:`s`.

    This forcing term has the property that as the phase converges to 0, it also converges to 0, allowing the
    linear part of the DMP equation to converge to the goal.
    """

    def __init__(self, cs, num_basis):
        """Initialize the discrete forcing term.

        Args:
            cs (CS): discrete canonical system
            num_basis (int): number of basis functions
        """
        # set canonical system
        if not isinstance(cs, DiscreteCS):
            raise TypeError("Expecting 'cs' to be an instance of DiscreteCS")
        self.cs = cs

        # set num_basis
        self.num_basis = num_basis

        # create weights
        weights = np.zeros(num_basis)  # default f=0

        # desired activations throughout time
        c = np.linspace(0, cs.T, num_basis)
        c = np.exp(-cs.alpha_s * c)

        # set variance of basis functions (this was found by trial and error by DeWolf)
        h = np.ones(num_basis) * num_basis**1.5 / c / cs.alpha_s

        basis = EBF(center=c, h=h)
        super(DiscreteForcingTerm, self).__init__(weights, basis)

    def compute(self, s):
        # call parent compute
        f = super(DiscreteForcingTerm, self).compute(s)
        # scale with phase s
        return f * s

    def train(self, f_target, plot=False):
        """Train the weights to match the given target forcing term

        Generate a set of weights over the basis functions such that the target forcing term trajectory is matched.

        Args:
            f_target (np.array): the desired forcing term trajectory
        """

        # calculate phase and basis functions
        s_track = self.cs.rollout()
        psi_track = self.psi(s_track)   # shape=TxM

        # efficiently calculate BF weights using LWR (Locally Weighted (Linear) Regression)
        # spatial scaling term
        for b in range(self.num_basis):
            numerator = np.sum(s_track * psi_track[:, b] * f_target)
            denominator = np.sum(s_track**2 * psi_track[:, b])
            self.w[b] = numerator / denominator

        self.w = np.nan_to_num(self.w)

        if plot:
            import matplotlib.pyplot as plt
            # plot the basis function activations
            plt.figure()
            plt.subplot(211)
            plt.plot(psi_track)
            plt.title('basis functions')

            # plot the desired forcing function vs approx for the first dmp
            plt.subplot(212)
            plt.title('discrete force')
            plt.plot(f_target, label='f_target', linewidth=2.5)
            plt.plot(self.compute(s_track), label='f_pred', linewidth=2.5)

            # weighted sum of basis functions
            wps = self.weighted_basis(s_track)
            plt.plot(wps, linewidth=0.5)

            plt.legend()
            plt.tight_layout()
            plt.show()


class RhythmicForcingTerm(ForcingTerm):
    r"""Rhythmic Forcing Term

    .. math:: f(s) = \frac{ sum_{i} \psi_i(s) w_i }{ \sum_i \psi_i(s) } a

    where :math:`w` are the learnable weight parameters, :math:`\psi` are the basis functions evaluated at the
    given input phase variable :math:`s`, and :math:`a` is the amplitude.

    When used with DMPs, it produces a limit cycle behavior.
    """

    def __init__(self, cs, num_basis, amplitude=1.):
        """
        Initialize the rhythmic forcing term.

        Args:
            cs (CS): rhythmic canonical system
            num_basis (int): number of basis functions
            amplitude (float): amplitude
        """
        # set canonical system
        if not isinstance(cs, RhythmicCS):
            raise TypeError("Expecting 'cs' to be an instance of RhythmicCS")
        self.cs = cs

        # set num_basis and amplitude
        self.num_basis = num_basis
        self.a = amplitude

        # create weights
        weights = np.zeros(num_basis,)  # default f=0

        # set the centre of the Gaussian basis functions to be spaced evenly
        c = np.linspace(0, cs.T, num_basis + 1)  # the '+1' is because it is rhythmic, c(0) = c(2pi)
        c = c[:-1]

        # set concentration of basis function (this was found by trial and error by DeWolf)
        h = np.ones(num_basis) * num_basis

        # create basis functions
        basis = CBF(center=c, h=h)
        super(RhythmicForcingTerm, self).__init__(weights, basis)

    def compute(self, s):
        # call parent compute
        f = super(RhythmicForcingTerm, self).compute(s)
        # scale with amplitude and return it
        return f * self.a

    def train(self, f_target, plot=False):
        """Train the weights to match the given target forcing term

        Generate a set of weights over the basis functions such that the target forcing term trajectory is matched.

        Args:
            f_target (np.array): the desired forcing term trajectory
            plot (bool): If True, it will plot.
        """

        # calculate phase and basis functions
        s_track = self.cs.rollout()
        psi_track = self.psi(s_track)   # shape=TxM

        # efficiently calculate BF weights using LWR (Locally Weighted (Linear) Regression)
        for b in range(self.num_basis):
            self.w[b] = (np.dot(psi_track[:, b], f_target) / (np.sum(psi_track[:, b])))  # + 1e-10))

        if plot:
            import matplotlib.pyplot as plt
            # plot the basis function activations
            plt.figure()
            plt.subplot(211)
            plt.plot(psi_track)
            plt.title('basis functions')

            # plot the desired forcing function vs approx for the first dmp
            plt.subplot(212)
            plt.title('rhythmic force')
            plt.plot(f_target, label='f_target', linewidth=2.5)
            plt.plot(self.compute(s_track), label='f_pred', linewidth=2.5)
            wps = self.weighted_basis(s_track)
            plt.plot(wps, linewidth=0.5)
            plt.legend()
            plt.tight_layout()
            plt.show()


# DMP #

class DMP(object):
    r"""Dynamic Movement Primitive

    Dynamic movement primitives (DMPs) are a set of differential equations (for each degree of freedoms (DoFs), i.e.
    general coordinates) that encodes a movement [1]. It is thought that movement primitives are the building blocks
    of a movement, and several evidences show that such modules exist in animals [2].

    DMPs are often formulated as a 2nd-order differential equation:

    .. math:: \tau^2 \ddot{y} = \alpha ( \beta (g - y) - \dot{y}) + f(s)

    or sometimes, as a first-order differential system:

    .. math::

            \tau \dot{z} &= \alpha ( \beta (g - y) - z) + f(s) \\
            \tau \dot{y} &= z

    They can also be rewritten as:

    .. math:: \tau^2 \ddot{y} = K (g - y) - D \tau \dot{y} + f(s)

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the reproduced movement, :math:`K`
    is the stiffness coefficient, :math:`D` is the damping coefficient, :math:`y, \dot{y}, \ddot{y}` are the position,
    velocity, and acceleration of a DoF, and :math:`f(s)` is the non-linear forcing term. These equations are also
    known as the transformation systems and represent, with the canonical system, DMPs.

    All of the above formulations are equivalent to each other. However, in my humble opinion, the last equation
    depicts better what the transformation system constitutes; it is a unit-mass spring-damper system or PD controller
    with a forcing term. This last term is non-linear and can be learned from the demonstrations.
    If the forcing is zero, then the differential equation is stable, and the position :math:`y` converges to the goal.
    The stiffness and damping coefficients (:math:`K` and :math:`D`) are often selected such that the whole system
    (without the forcing term) is critically damped (:math:`D = 2 \sqrt{K}`). Other behaviors can be obtained by
    selecting the stiffness and damping coefficient such that we obtain:
    * an undamped system: :math:`D = 0` or :math:`K \rightarrow \infty`
    * an underdamped system: :math:`D < 2 \sqrt{K}`
    * a critically damped system: :math:`D = 2 \sqrt{K}`
    * an overdamped system: :math:`D > 2 \sqrt{K}`

    Because the last formulation is more intuitive (at least for me), it will be used in this class.
    Imitation is performed by learning the forcing term.

    DMPs can be categorized in two main categories:
    * discrete DMP: used to represent discrete movements such as such as reaching, pushing/pulling, etc.
    * rhythmic DMP: used to represent rhythmic movements such as walking, running dribbling, sewing, etc.

    DMP have the following nice properties:
    * translation invariant
    * linear parameters but still allows to represent non-linear movements

    Here are few limitations/shortcomings:
    * hard to couple sensory information with it
    * have to come up with the number of basis functions

    For a more biologically-inspired DMP [5] which allows to adapt the goal in real-time and a better rescaling, see
    the `BioDMP` class.

    Note that this code was inspired by the `pydmps` code [2,3], but differ in several ways, notably:
    - we undertake a more object-oriented programming (OOP) approach
    - the equations are a little bit differents (e.g. :math:`tau`) in which we use the ones presented in the refs
    - we decouple the Euler's method time step with the time step for the number of data points
    - timesteps: we go from 0 to T included, while DeWolf goes from 0 to T-1
    - we use array operation instead of iterating over each element to update them
    - we enforce consistency between the various methods and data structures
    - we implement `BioDMP` which allows to adapt and rescale the goal in real-time based on [4]
    - we implemented DMP sequencing based on [5]
    - we implemented DMP that can be used with orientations based on [7]
    - phase nodes which allows to couple phases, such as done in [8] for locomotion
    - it can be used with RL algorithms, notably PoWER [9] and PI^2 [10]

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
        [2] "Motor primitives in vertebrates and invertebrates", Flash et al., 2005
        [3] Tutorials on DMP: https://studywolf.wordpress.com/category/robotics/dynamic-movement-primitive/
        [4] PyDMPs (from DeWolf, 2013): https://github.com/studywolf/pydmps
        [5] "Biologically-inspired Dynamical Systems for Movement Generation: Automatic Real-time Goal Adaptation
            and Obstacle Avoidance", Hoffmann et al., 2009
        [6] "Action Sequencing using Dynamic Movement Primitives", Nemec et al., 2011
        [7] "Orientation in Cartesian Space Dynamic Movement Primitives", Ude et al., 2014
        [8] "A Framework for Learning Biped Locomotion with Dynamical Movement Primitives", Nakanishi et al., 2004
        [9] "Policy Search for Motor Primitives in Robotics", Kober et al., 2010
        [10] "A Generalized Path Integral Control Approach to Reinforcement Learning", Theodorou et al., 2010
    """

    def __init__(self, canonical_system, forcing_term, y0=0, goal=1, stiffness=None, damping=None):
        """Initialize the DMP.

        Args:
            canonical_system (CS): canonical system which drives the DMP transformation system
            forcing_terms (list): list of forcing terms (one forcing term for each DMP). Each forcing term can have
                different number of basis functions.
            y0 (float, float[M]): initial state of DMPs
            goal (float, float[M]): goal state of DMPs
            stiffness (float): stiffness term in the transformation system for DMPs
            damping (float): damping term in the transformation system for DMPs
        """

        self.cs = canonical_system

        if isinstance(forcing_term, ForcingTerm):
            forcing_term = [forcing_term]
        elif isinstance(forcing_term, (list, tuple)):
            for f in forcing_term:
                if not isinstance(f, ForcingTerm):
                    raise TypeError("An item in the iterable is not an instance of ForcingTerm.")
        else:
            raise TypeError("Expecting forcing term to be an instance of ForcingTerm or a list/tuple of ForcingTerm")

        self.f = forcing_term
        self.num_dmps = len(forcing_term)
        self.dt = self.cs.dt
        self.timesteps = self.cs.timesteps

        # check initial and goal positions # TODO use property to set them
        if isinstance(y0, (int, float)):
            y0 = np.ones(self.num_dmps) * y0
        if isinstance(y0, (list, tuple)):
            y0 = np.array(y0)
        self.y0 = y0
        self.dy0 = np.zeros(self.num_dmps)
        self.ddy0 = np.zeros(self.num_dmps)
        if isinstance(goal, (int, float)):
            goal = np.ones(self.num_dmps) * goal
        elif isinstance(goal, (list, tuple)):
            goal = np.array(goal)
        self.goal = goal
        self._check_offset()

        # set stiffness and damping coefficient (if not specified, make them critically damped, i.e. D=2\sqrt{K})
        self.D = np.ones(self.num_dmps) * 25. if damping is None else damping
        self.K = self.D**2 / 4. if stiffness is None else stiffness

        # set up the DMP system
        self.prev_s = self.cs.init_phase
        self.reset()

        # target forcing term (keep a copy)
        self.f_target = None

    def __repr__(self):
        return self.__class__.__name__

    def __call__(self, *args, **kwargs):
        return self.step(*args, **kwargs)

    ##############
    # Properties #
    ##############

    @property
    def num_parameters(self):
        """Return the total number of parameters"""
        return np.array([force.w for force in self.f]).size

    ##################
    # Static Methods #
    ##################

    @staticmethod
    def copy(other):
        if not isinstance(other, DMP):
            raise TypeError("Trying to copy an object which is not a DMP")

    @staticmethod
    def is_parametric():
        """
        Return True as a DMP has weights that need to be optimized.
        """
        return True

    @staticmethod
    def is_linear():
        """
        Return True as a DMP is linear in terms of its weights (i.e. learnable parameters)
        """
        return True

    @staticmethod
    def is_recurrent():
        """
        Return False.
        """
        return False

    @staticmethod
    def is_probabilistic():
        """The DMP is a deterministic model"""
        return False

    @staticmethod
    def is_discriminative():
        """The DMP is a discriminative model which predicts the output :math:`y` given the input :math:`x`"""
        return True

    @staticmethod
    def is_generative():
        """The DMP is not a generative model"""
        return False

    ###########
    # Methods #
    ###########

    def parameters(self):
        """Returns an iterator over the model parameters."""
        for force in self.f:
            yield force.w

    def named_parameters(self):
        """Returns an iterator over the model parameters, yielding both the name and the parameter itself"""
        for force in self.f:
            yield str(force), force.w

    def list_parameters(self):
        """Return a list of parameters"""
        return list(self.parameters())

    def get_vectorized_parameters(self, to_numpy=True):
        """Return a vectorized form (1 dimensional array) of the parameters."""
        parameters = self.parameters()
        vector = np.concatenate([parameter.reshape(-1) for parameter in parameters])  # np.concatenate = torch.cat
        # if to_numpy:
        #     return vector.detach().numpy()
        return vector

    def set_vectorized_parameters(self, vector):
        """Set the vector parameters."""
        # convert the vector to torch array
        # if isinstance(vector, np.ndarray):
        #     vector = torch.from_numpy(vector).float()

        # set the parameters from the vectorized one
        # idx = 0
        # for parameter in self.parameters():
        #     size = parameter.nelement()
        #     parameter.data = vector[idx:idx+size].reshape(parameter.shape)
        #     idx += size

        # set the parameters from the vectorized one
        idx = 0
        for force in self.f:
            size = force.w.size
            force.w = vector[idx:idx+size].reshape(force.w.shape)
            idx += size

    def get_damping_ratio(self):
        """
        Return the damping ratio :math:`\zeta = D / D_c` where :math:`D_c = 2 \sqrt{K}`.

        * if :math:`\zeta` = 0, the system is undamped (i.e. no damping)
        * if :math:`\zeta` < 1, the system is underdamped (i.e. there will be some oscillations)
        * if :math:`\zeta` = 1, the system is critically damped (i.e. return to equilibrium as fast as possible
          without oscillating).
        * if :math:`\zeta` > 1, the system is overdamped (i.e. the system returns to equilibrium without oscillating
          but might be slow depending on the damping value).
        """
        return self.D / (2*np.sqrt(self.K))

    def _check_offset(self):
        """Check to see if the initial position and goal are the same. If that is the case, offset slightly so that
        the forcing term is not 0. Otherwise, look at the `BioDMP` class.
        """
        self.goal[self.y0 == self.goal] += 1e-4

    def get_scaling_term(self, new_goal=None):
        # this is overridden by the child classes
        return np.ones(self.num_dmps)

    def _generate_goal(self, y_des):
        raise NotImplementedError()

    def reset(self):
        """Reset the transformation and canonical systems"""
        self.y = self.y0.copy()
        self.dy = self.dy0.copy()  # np.zeros(self.num_dmps)
        self.ddy = self.ddy0.copy()
        self.prev_s = self.cs.reset()

    def step(self, s=None, tau=1.0, error=0.0, forcing_term=None, new_goal=None, external_force=None, rescale_force=True):
        """Run the DMP transformation system for a single time step.

        Args:
            s (None, float): the phase value. If None, it will use the canonical system.
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            error (float): optional system feedback
            forcing_term (float[M]): if given, it will replace the forcing term (where `M` = number of DMPs)
            new_goal (float[M]): new goal (where `M` = number of DMPs)
            rescale_force (bool): if the given forcing term should be rescaled.
        """

        # system feedback
        error_coupling = 1.0 / (1.0 + error)

        # get phase from canonical system
        if s is None:
            s = self.cs.step(tau=tau, error_coupling=error_coupling)
        elif not isinstance(s, (float, int)):
            raise TypeError("Expecting the phase 's' to be a float or integer. Instead, I got {}".format(type(s)))

        # check if same phase as before
        if s == self.prev_s:
            return self.y, self.dy, self.ddy

        if new_goal is None:
            new_goal = self.goal

        # save previous position and velocity
        prev_y, prev_dy = self.y.copy(), self.dy.copy()

        # compute scaling factor for the forcing term
        scaling = self.get_scaling_term(new_goal)

        # for each DMP, solve transformation system equation using Euler's method
        for d in range(self.num_dmps):

            # compute forcing term
            if forcing_term is None:
                # f = self.f[d](s) * scaling[d]
                f = self.f_gen(s) * scaling[d]
            else:
                if rescale_force:
                    f = forcing_term[d] * scaling[d]
                else:
                    f = forcing_term[d]

            # DMP acceleration
            self.ddy[d] = self.K[d]/(tau**2) * (new_goal[d] - self.y[d]) - self.D[d]/tau * self.dy[d] + f/(tau**2)
            if external_force is not None:
                self.ddy[d] += external_force[d]
            self.dy[d] += self.ddy[d] / tau * self.dt * error_coupling
            self.y[d] += self.dy[d] * self.dt * error_coupling

        # return self.y, self.dy, self.ddy
        return prev_y, prev_dy, self.ddy

    def rollout(self, timesteps=None, tau=1.0, error=0.0, forcing_term=None, new_goal=None, rescale_force=True,
                **kwargs):
        """Generate position, velocity, and acceleration trajectories, no feedback is incorporated.

        Args:
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            timesteps (None, int): the number of steps to perform
            error (float): optional system feedback
            forcing_term (np.ndarray): if given, it will replace the forcing term (shape [num_dmps, timesteps])
            new_goal (np.ndarray): new goal (of shape [num_dmps,])

        Returns:
            float[M,T]: y (position) trajectories
            float[M,T]: dy (velocity) trajectories
            float[M,T]: ddy (acceleration) trajectories
        """

        # reset the canonical and transformation systems
        self.reset()

        if timesteps is None:
            timesteps = int(self.timesteps * tau)

        # set up tracking vectors
        y_track = np.zeros((self.num_dmps, timesteps))
        dy_track = np.zeros((self.num_dmps, timesteps))
        ddy_track = np.zeros((self.num_dmps, timesteps))

        # for the other timesteps, solve DMP equation using Euler's method
        for t in range(timesteps):
            if forcing_term is None:
                y, dy, ddy = self.step(tau=tau, error=error, new_goal=new_goal, external_force=None)
            else:
                y, dy, ddy = self.step(tau=tau, error=error, forcing_term=forcing_term[:, t], new_goal=new_goal,
                                       rescale_force=rescale_force)

            # record timestep
            y_track[:, t] = y
            dy_track[:, t] = dy
            ddy_track[:, t] = ddy

        return y_track, dy_track, ddy_track

    def train(self, f_target):
        """Train the forcing terms."""
        # train each forcing term
        if f_target.shape[0] != len(self.f):
            raise ValueError("Mismatch between the number of forcing terms")

        # train each forcing term
        for forcing_term, target in zip(self.f, f_target):
            forcing_term.train(target)

    def imitate(self, y_des, dy_des=None, ddy_des=None, interpolation='cubic', plot=False):
        """Imitate a desired trajectory, and learn the parameters that best realizes it.

        Args:
            y_des (np.array): the desired position trajectories of each DMP with shape [num_dmps, timesteps]
            dy_des (np.array): the desired velocities with shape [num_dmps, timesteps]
            ddy_des (np.array): the desired accelerations with shape [num_dmps, timesteps]
            interpolation (str): how to interpolate the data. Select between 'linear', 'cubic', and 'hermite'.
        """

        # set initial state and goal
        if y_des.ndim == 1:
            y_des = y_des.reshape(1, len(y_des))
        self.y0 = y_des[:, 0].copy()
        self.goal = self._generate_goal(y_des)
        self._check_offset()

        timesteps = y_des.shape[1]

        def interpolate(x, dt, period, timesteps, new_timesteps, interpolation=interpolation, return_gen=False):
            # generate function to interpolate the desired trajectory
            t = np.linspace(0, period, timesteps)
            if interpolation == 'linear':  # use linear interpolation
                path_gen = scipy.interpolate.interp1d(t, x, axis=-1)
            elif interpolation == 'cubic':  # use cubic spline interpolation
                path_gen = scipy.interpolate.CubicSpline(t, x, axis=-1)
            else:  # TODO: implement hermite (see utils.interpolator.hermite)
                raise ValueError("The requested interpolation has not been implemented. Select between 'linear' or "
                                 "'cubic'")
            if return_gen:
                return path_gen
            return path_gen([t * self.dt for t in range(new_timesteps)])

        y_des = interpolate(y_des, self.dt, self.cs.T, timesteps, self.timesteps, interpolation=interpolation)

        # compute desired velocity if necessary
        if dy_des is None:
            # calculate velocity of y_des
            dy_des = np.diff(y_des) / self.dt
            # add zero to the beginning of every row
            print(dy_des.shape)
            dy_des = np.hstack((np.zeros((self.num_dmps, 1)), dy_des))
        else:
            if dy_des.ndim == 1:
                dy_des = dy_des.reshape(1, len(dy_des))
            dy_des = interpolate(dy_des, self.dt, self.cs.T, dy_des.shape[1], self.timesteps,
                                 interpolation=interpolation)
        self.dy0 = dy_des[:, 0].copy()

        # compute desired acceleration if necessary
        if ddy_des is None:
            # calculate acceleration of y_des
            ddy_des = np.diff(dy_des) / self.dt
            # add zero to the beginning of every row
            ddy_des = np.hstack((np.zeros((self.num_dmps, 1)), ddy_des))
        else:
            if ddy_des.ndim == 1:
                ddy_des = ddy_des.reshape(1, len(ddy_des))
            ddy_des = interpolate(ddy_des, self.dt, self.cs.T, ddy_des.shape[1], self.timesteps,
                                  interpolation=interpolation)
        self.ddy0 = ddy_des[:, 0].copy()

        # find the force required to move along this trajectory (with shape [num_dmps, timesteps])
        f_target = ddy_des - self.K.reshape(-1, 1) * (self.goal.reshape(-1,1) - y_des) + self.D.reshape(-1, 1) * dy_des

        # plot
        if plot:
            import matplotlib.pyplot as plt
            plt.figure()
            plt.plot(y_des[0], 'b', label='pos')
            plt.plot(dy_des[0], 'g', label='vel')
            plt.plot(ddy_des[0], 'r', label='acc')
            plt.plot(f_target[0], 'k', label='force')
            plt.legend()
            plt.show()

        self.f_gen = interpolate(f_target, self.dt, self.cs.T, ddy_des.shape[1], 2000,
                                 interpolation=interpolation, return_gen=True)

        # efficiently generate weights to realize f_target
        self.f_target = f_target
        self.train(f_target)

        # reset the canonical and transformation systems
        self.reset()

        return y_des

    def get_forcing_term(self, s):
        """
        Get the forcing terms based on the given phase value.

        Args:
            s (float, float[T]): phase value(s)

        Returns:
            float[M], float[M,T]: forcing terms
        """
        return np.array([self.f[d](s) for d in range(self.num_dmps)])

    def generate_goal(self, y0=None, dy0=None, ddy0=None, f0=None):
        """
        Generate the goal from the initial positions, velocities, accelerations, and forces.

        Args:
            y0 (float[M], None): initial positions. If None, it will take the default initial positions.
            dy0 (float[M], None): initial velocities. If None, it will take the default initial velocities.
            ddy0 (float[M], None): initial accelerations. If None, it will take the default initial accerelations.
            f0 (float[M], None): initial forcing terms. If None, it will compute it based on the learned weights.
                You can also give `dmp.f_target[:,0]` to get the correct goal.

        Returns:
            float[M]: goal position for each DMP.
        """
        if y0 is None:
            y0 = self.y0
        if dy0 is None:
            dy0 = self.dy0
        if ddy0 is None:
            ddy0 = self.ddy0
        if f0 is None:
            s0 = self.cs.init_phase
            f0 = self.get_forcing_term(s0)

        return 1/self.K * (ddy0 + self.D * dy0 + self.K * y0 - f0)

    def sequence(self, model, mode=0):
        """
        Define how to sequence with another DMP model.

        Args:
            model (DMP): DMP model
            mode (int): specifies how to sequence the two DMP models.

        Returns:
            DMP: the sequenced model

        References:
            [1] "Action Sequencing using Dynamic Movement Primitives", Nemec et al., 2011
        """
        if not isinstance(model, DMP):
            raise TypeError("The given model is not an instance of DMP.")
        pass

    # def __rshift__(self, other):
    #     """
    #     Sequence DMP model with another learning model.
    #
    #     Ref: "Action Sequencing using Dynamic Movement Primitives", Nemec et al., 2011
    #
    #     :param other: another DMP model
    #     :return:
    #     """
    #     # If we sequence two DMP models
    #     if isinstance(other, DMP):
    #
    #     else:
    #         # if it is another model, call the parent's method which knows how to sequence different models
    #         super(DMP, self).__rshift__(other)


class DiscreteDMP(DMP):
    r"""Discrete Dynamic Movement Primitive

    Discrete DMPs have the same mathematical formulation as general DMPs, which is given by:

    .. math:: \tau^2 \ddot{y} = K (g - y) - D \tau \dot{y} + f(s) (g - y0)

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the reproduced movement, :math:`K`
    is the stiffness coefficient, :math:`D` is the damping coefficient, :math:`y, \dot{y}, \ddot{y}` are the position,
    velocity, and acceleration of a DoF, and :math:`f(s)` is the non-linear forcing term.

    However, the forcing term in the case of discrete DMPs is given by:

    .. math:: f(s) = \frac{\sum_i \psi_i(s) w_i}{\sum_i \psi_i(s)} s

    where :math:`w` are the learnable weight parameters, and :math:`\psi` are the basis functions evaluated at the
    given input phase variable :math:`s`, :math:`g` is the goal, and :math:`y_0` is the initial position. Note that
    as the phase converges to 0, the forcing term also converges to that value.

    The basis functions (in the discrete case) are given by:

    .. math:: \psi_i(s) = \exp \left( - \frac{1}{2 \sigma_i^2} (x - c_i)^2 \right)

    where :math:`c_i` is the center of the basis function :math:`i`, and :math:`\sigma_i` is its width.

    Also, the canonical system associated with this transformation system is given by:

    .. math:: \tau \dot{s} = - \alpha_s s

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the movement, :math:`s` is the phase
    variable that drives the DMP, and :math:`\alpha_s` is a predefined constant.

    All these differential equations are solved using Euler's method.

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
    """

    def __init__(self, num_dmps, num_basis, dt=0.01, y0=0, goal=1,
                 forcing_terms=None, stiffness=None, damping=None):
        """Initialize the discrete DMP

        Args:
            num_dmps (int): number of DMPs
            num_basis (int, int[M]): number of basis functions, or list of number of basis functions.
            dt (float): step integration for Euler's method
            y0 (float, float[M]): initial position(s)
            goal (float, float[M]): goal(s)
            forcing_terms (list, ForcingTerm): the forcing terms (which can have different basis functions)
            stiffness (float): stiffness coefficient
            damping (float): damping coefficient
        """

        # create discrete canonical system
        cs = DiscreteCS(dt=dt)

        # create forcing terms (each one contains the basis functions and learnable weights)
        if forcing_terms is None:
            if isinstance(num_basis, int):
                forcing_terms = [DiscreteForcingTerm(cs, num_basis) for _ in range(num_dmps)]
            else:
                if not isinstance(num_basis, (np.ndarray, list, tuple, set)):
                    raise TypeError("Expecting 'num_basis' to be an int, list, tuple, np.array or set.")
                if len(num_basis) != num_dmps:
                    raise ValueError("The length of th list of number of basis doesn't match the number of DMPs")
                forcing_terms = [DiscreteForcingTerm(cs, n_basis) for n_basis in num_basis]

        # call super class constructor
        super(DiscreteDMP, self).__init__(canonical_system=cs, forcing_term=forcing_terms, y0=y0, goal=goal,
                                          stiffness=stiffness, damping=damping)

    def get_scaling_term(self, new_goal=None):
        """
        Return the scaling term for the forcing term.

        Args:
            new_goal (float, float[M], None): the new goal position. If None, it will be the current goal.

        Returns:
            float, float[M]: scaling term
        """
        if new_goal is None:
            new_goal = self.goal
        return (new_goal - self.y0) / (self.goal - self.y0)

    def _generate_goal(self, y_des):
        """Generate the goal for path imitation.

        Args:
            y_des (np.array): the desired trajectory to follow with shape [num_dmps, timesteps]

        Returns:
            float[M]: goal position
        """
        return np.copy(y_des[:, -1])


class RhythmicDMP(DMP):
    r"""Rhythmic Dynamic Movement Primitive

    Rhythmic DMPs have the same mathematical formulation as general DMPs, which is given by:

    .. math:: \tau^2 \ddot{y} = K (g - y) - D \tau \dot{y} + f(s)

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the reproduced movement, :math:`K`
    is the stiffness coefficient, :math:`D` is the damping coefficient, :math:`y, \dot{y}, \ddot{y}` are the position,
    velocity, and acceleration of a DoF, and :math:`f(s)` is the non-linear forcing term.

    However, the forcing term in the case of rhythmic DMPs is given by:

    .. math:: f(s) = \frac{\sum_i \psi_i(s) w_i}{\sum_i \psi_i(s)} a

    where :math:`w` are the learnable weight parameters, and :math:`\psi` are the basis functions evaluated at the
    given input phase variable :math:`s`, and :math:`a` is the amplitude.

    The basis functions (in the rhythmic case) are given by:

    .. math:: \psi_i(s) = \exp \left( - h_i (\cos(s - c_i) - 1) \right)

    where :math:`c_i` is the center of the basis, and :math:`h_i` is a measure of concentration.

    Also, the canonical system associated with this transformation system is given by:

    .. math:: \tau \dot{s} = 1

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the movement, and :math:`s` is the
    phase variable that drives the DMP.

    All these differential equations are solved using Euler's method.

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
    """

    def __init__(self, num_dmps, num_basis, dt=0.01, y0=0, goal=1,
                 forcing_terms=None, stiffness=None, damping=None):
        """Initialize the rhythmic DMP

        Args:
            num_dmps (int): number of DMPs
            num_basis (int): number of basis functions
            dt (float): step integration for Euler's method
            y0 (float, np.array): initial position(s)
            goal (float, np.array): goal(s)
            forcing_terms (list, ForcingTerm): the forcing terms (which can have different basis functions)
            stiffness (float): stiffness coefficient
            damping (float): damping coefficient
        """

        # create rhythmic canonical system
        cs = DiscreteCS(dt=dt)

        # create forcing terms (each one contains the basis functions and learnable weights)
        if forcing_terms is None:
            if isinstance(num_basis, int):
                forcing_terms = [RhythmicForcingTerm(cs, num_basis) for _ in range(num_dmps)]
            else:
                if not isinstance(num_basis, (np.ndarray, list, tuple, set)):
                    raise TypeError("Expecting 'num_basis' to be an int, list, tuple, np.array or set.")
                if len(num_basis) != num_dmps:
                    raise ValueError("The length of th list of number of basis doesn't match the number of DMPs")
                forcing_terms = [RhythmicForcingTerm(cs, n_basis) for n_basis in num_basis]

        # call super class constructor
        super(RhythmicDMP, self).__init__(canonical_system=cs, forcing_term=forcing_terms, y0=y0, goal=goal,
                                          stiffness=stiffness, damping=damping)

    def get_scaling_term(self, new_goal=None):
        """
        Return the scaling term for the forcing term. For rhythmic DMPs it's non-diminishing, so this function just
        returns 1.
        """
        return np.ones(self.num_dmps)

    def _generate_goal(self, y_des):
        """Generate the goal for path imitation.

        For rhythmic DMPs, the goal is the average of the desired trajectory.

        Args:
            y_des (float[M,T]): the desired trajectory to follow (with shape [num_dmps, timesteps])

        Returns:
            float[M]: goal positions (one for each DMP)
        """
        goal = np.zeros(self.num_dmps)
        for n in range(self.num_dmps):
            num_idx = ~np.isnan(y_des[n])  # ignore nan's when calculating goal
            goal[n] = .5 * (y_des[n, num_idx].min() + y_des[n, num_idx].max())
        return goal


class BioDiscreteDMP(DiscreteDMP):
    r"""Biologically-inspired Discrete DMPs

    One of the main problems with the initial DMP formulation is when some goal coordinates coincide with their
    corresponding initial position coordinates, it results in an inappropriate rescaling when displacing a little bit
    the goal.

    To deal with this problem, a new formulation of the transformation system was proposed in [2] and is given by:

    .. math:: \tau^2 \ddot{y} = K (g - y) - D \tau \dot{y} - K(g - y_0)s + K f(s)

    where :math:`\tau` is a scaling factor that allows to slow down or speed up the reproduced movement, :math:`K`
    is the stiffness coefficient, :math:`D` is the damping coefficient, :math:`y, \dot{y}, \ddot{y}` are the position,
    velocity, and acceleration of a DoF, and :math:`f(s)` is the non-linear forcing term.

    The forcing term is expressed as:

    .. math:: f(s) = \frac{\sum_i \psi_i(s) w_i}{ \sum_j \psi_j(s)} s

    Properties (from [2]):
    * Invariant under affine transformation
    * Movement generalization to new targets

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
        [2] "Biologically-inspired Dynamical Systems for Movement Generation: Automatic Real-time Goal Adaptation
             and Obstacle Avoidance", Hoffmann et al., 2009
        [3] "Learning and Generalization of Motor Skills by Learning from Demonstration", Pastor et al., 2009
    """

    def __init__(self, num_dmps, num_basis, dt=0.01, y0=0, goal=1,
                 forcing_terms=None, stiffness=None, damping=None):
        """Initialize the discrete DMP

        Args:
            num_dmps (int): number of DMPs
            num_basis (int): number of basis functions
            dt (float): step integration for Euler's method
            y0 (float, np.array): initial position(s)
            goal (float, np.array): goal(s)
            forcing_terms (list, ForcingTerm): the forcing terms (which can have different basis functions)
            stiffness (float): stiffness coefficient
            damping (float): damping coefficient
        """
        # if stiffness is None and damping is None:
        #     # from paper [2]
        #     stiffness = 150 * np.ones(num_dmps)
        #     damping = 2 * np.sqrt(stiffness)

        self.cst = 0.75     # this depends on the K and D value

        super(BioDiscreteDMP, self).__init__(num_dmps, num_basis, dt=dt, y0=y0, goal=goal,
                                             forcing_terms=forcing_terms, stiffness=stiffness, damping=damping)

    def step(self, s=None, tau=1.0, error=0.0, forcing_term=None, new_goal=None, external_force=None):
        """Run the DMP transformation system for a single time step.

        Args:
            s (None, float): the phase value. If None, it will use the canonical system.
            tau (float): Increase tau to make the system slower, and decrease it to make it faster
            error (float): optional system feedback
            forcing_term (np.ndarray): if given, it will replace the forcing term (shape [dmp,])
            new_goal (np.ndarray): new goal (of shape [num_dmps,])
        """

        # system feedback
        error_coupling = 1.0 / (1.0 + error)

        # get phase from canonical system
        if s is None:
            s = self.cs.step(tau=tau, error_coupling=error_coupling)
        elif not isinstance(s, (float, int)):
            raise TypeError("Expecting the phase 's' to be a float or integer. Instead, I got {}".format(type(s)))

        # check if same phase as before
        if s == self.prev_s:
            return self.y, self.dy, self.ddy

        if new_goal is None:
            new_goal = self.goal
        else:
            new_goal = new_goal + self.cst * (new_goal - self.goal)

        # save previous position and velocity
        prev_y, prev_dy = self.y.copy(), self.dy.copy()

        # for each DMP, solve transformation system equation using Euler's method
        for d in range(self.num_dmps):

            # compute forcing term
            if forcing_term is None:
                f = self.f[d](s) + self.K[d] * s * (self.goal[d] - new_goal[d])
            else:
                f = forcing_term[d]

            # DMP acceleration
            self.ddy[d] = self.K[d]/(tau**2) * (new_goal[d] - self.y[d]) - self.D[d]/tau * self.dy[d] + f/(tau**2)
            if external_force is not None:
                self.ddy[d] += external_force[d]
            self.dy[d] += self.ddy[d] / tau * self.dt * error_coupling
            self.y[d] += self.dy[d] * self.dt * error_coupling

        # return self.y, self.dy, self.ddy
        return prev_y, prev_dy, self.ddy

    def _check_offset(self):
        """No need to check for an offset with this class"""
        pass

    def generate_goal(self, y0=None, dy0=None, ddy0=None, f0=None):
        """
        Generate the goal from the initial positions, velocities, accelerations, and forces.

        Args:
            y0 (float[M], None): initial positions. If None, it will take the default initial positions.
            dy0 (float[M], None): initial velocities. If None, it will take the default initial velocities.
            ddy0 (float[M], None): initial accelerations. If None, it will take the default initial accerelations.
            f0 (float[M], None): initial forcing terms. If None, it will compute it based on the learned weights.
                You can also give `dmp.f_target[:,0]` to get the correct goal.

        Returns:
            float[M]: goal position for each DMP.
        """
        if y0 is None:
            y0 = self.y0
        if dy0 is None:
            dy0 = self.dy0
        if ddy0 is None:
            ddy0 = self.ddy0
        if f0 is None:
            s0 = self.cs.init_phase
            f0 = self.get_forcing_term(s0)

        return 1/self.K * (ddy0 + self.D * dy0 + self.K * y0 - self.K * f0)


# Methods #
# TODO: check other methods in my various files

def obstacle_avoidance(y, dy, goal, obstacles):
    """Obstacle avoidance using formulation in [1,2].

    This is taken from [3] and generalized to 3D. This returns the coupling term.

    .. math:: p(y,dy) = \gamma R dy \phi \exp(-\beta \phi)

    Args:
        y (np.ndarray): position at one time step
        dy (np.ndarray): velocity at one time step
        goal (np.ndarray): goal position
        obstacles (list on np.ndarray): list of obstacle positions

    Returns:
        np.array: coupling term p(y,dy)

    References:
        [1] "Dynamical movement primitives: Learning attractor models for motor behaviors", Ijspeert et al., 2013
        [2] "Biologically-inspired Dynamical Systems for Movement Generation: Automatic Real-time Goal Adaptation
             and Obstacle Avoidance", Hoffmann et al., 2009
        [3] PyDMPs, DeWolf, 2013: https://github.com/studywolf/pydmps/blob/master/examples/avoid_obstacles.py
    """
    # TODO: generalize to 3D
    # TODO: improve it by considering moving obstacles (see paper [2])

    # define few variables
    beta = 20.0 / np.pi
    gamma = 100.

    # init coupling term
    p = np.zeros(len(y))

    for obstacle in obstacles:
        # if we're moving
        if np.linalg.norm(dy) > 1e-5:

            # get the angle we're heading in
            phi_dy = -np.arctan2(dy[1], dy[0])
            R_dy = np.array([[np.cos(phi_dy), -np.sin(phi_dy)],
                             [np.sin(phi_dy), np.cos(phi_dy)]])
            # calculate vector to object relative to body
            obj_vec = obstacle - y
            # rotate it by the direction we're going
            obj_vec = np.dot(R_dy, obj_vec)
            # calculate the angle of obj relative to the direction we're going
            phi = np.arctan2(obj_vec[1], obj_vec[0])

            dphi = gamma * phi * np.exp(-beta * abs(phi))
            R = np.dot(R_halfpi, np.outer(obstacle - y, dy))
            pval = -np.nan_to_num(np.dot(R, dy) * dphi)

            # check to see if the distance to the obstacle is further than
            # the distance to the target, if it is, ignore the obstacle
            if np.linalg.norm(obj_vec) > np.linalg.norm(goal - y):
                pval = 0

            p += pval

    return p


def automatic_num_basis(ydes, dmpClass, init_guess=10, tolerance=0.0001, debug=True, plot=False):
    """
    Automatic discovery of the 'optimal' number of basis functions.

    Args:
        ydes (float[M,T]): desired position trajectory. `M` is the number of basis functions, and `T` is the length
            of the trajectory.
        init_guess (int): initial guess for the number of basis function
        tolerance (float): acceptable tolerance for the MSE between the desired and predicted position trajectory.

    Returns:
        int: optimal number of basis functions to use.
    """
    ydes = np.array(ydes)
    prev_mse = np.sum(ydes ** 2)
    prev_num_basis = int(init_guess / 2)
    num_basis = init_guess
    num_dmps = ydes.shape[0]

    mses, bfs = [], []

    while True:
        # Evaluate the DMP with the specified nb of basis fcts
        dmp = dmpClass(num_dmps=num_dmps, num_basis=num_basis)
        dmp.imitate(y_des=ydes)
        y = dmp.rollout(tau=1.0)
        mse = np.sum((ydes - y)**2)
        mses.append(mse)
        bfs.append(num_basis)

        if debug:
            print("Num basis: {} - MSE: {}".format(num_basis, mse))

        num_basis_tmp = num_basis
        if prev_num_basis < num_basis:
            if mse < prev_mse:
                # can maybe still improve the MSE by increasing 2 times the number of basis functions
                num_basis += 2 * (num_basis - prev_num_basis)
            else:  # mse >= prev_mse
                # we jumped too much forward, backtrack from half
                num_basis -= int((num_basis - prev_num_basis) / 2)
        elif prev_num_basis > num_basis:
            if mse <= prev_mse:
                # can maybe still improve the MSE by decreasing by half the number of basis functions
                num_basis -= int((prev_num_basis - num_basis) / 2)
            else:  # mse > prev_mse
                if abs(prev_mse - mse) < tolerance:
                    break
                # otherwise, we jumped too much backward, backtrack from half
                num_basis += int((prev_num_basis - num_basis) / 2)
        else:
            break

        prev_num_basis = num_basis_tmp
        prev_mse = mse

    if debug:
        print("Best number of basis: {} - with MSE: {}".format(num_basis, mse))

    if plot:
        plt.subplot(1, 2, 1)
        plt.title('Number of basis')
        plt.plot(bfs)
        plt.subplot(1, 2, 2)
        plt.title('MSE')
        plt.subplot(1, 2, 2)
        plt.show()

    return num_basis


# Tests
if __name__ == '__main__':
    import matplotlib.pyplot as plt

    # tests canonical systems
    discrete_cs = DiscreteCS()
    rhythmic_cs = RhythmicCS()

    # check tau
    plt.subplot(1, 2, 1)
    plt.title('Discrete CS')
    for tau in [1., 0.5, 2.]:
        rollout = discrete_cs.rollout(tau=tau)
        plt.plot(np.linspace(0, 1., len(rollout)), rollout, label='tau='+str(tau))
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.title('Rhythmic CS')
    for tau in [1., 0.5, 2.]:
        rollout = rhythmic_cs.rollout(tau=tau)
        plt.plot(np.linspace(0, 1., len(rollout)), rollout, label='tau='+str(tau))
    plt.legend()
    plt.show()

    # tests basis functions
    num_basis = 20
    discrete_f = DiscreteForcingTerm(discrete_cs, num_basis)
    rhythmic_f = RhythmicForcingTerm(rhythmic_cs, num_basis)
    plt.subplot(1, 2, 1)
    rollout = discrete_cs.rollout()
    plt.title('discrete basis fcts')
    plt.plot(rollout, discrete_f.psi(rollout))
    plt.subplot(1, 2, 2)
    rollout = rhythmic_cs.rollout()
    plt.title('rhythmic basis fcts')
    plt.plot(rollout, rhythmic_f.psi(rollout))
    plt.show()

    # tests forcing terms
    f = np.sin(np.linspace(0, 2*np.pi, 100))
    discrete_f.train(f, plot=True)
    f = np.sin(np.linspace(0, 2*np.pi, int(2*np.pi*100)))
    rhythmic_f.train(f, plot=True)

    # Test discrete DMP
    discrete_dmp = DiscreteDMP(num_dmps=1, num_basis=num_basis)
    t = np.linspace(-6, 6, 100)
    y_target = 1 / (1 + np.exp(-t))
    discrete_dmp.imitate(y_target)
    y, dy, ddy = discrete_dmp.rollout()

    plt.plot(y_target, label='y_target')
    plt.plot(y[0], label='y_pred')
    # plt.plot(dy[0])
    # plt.plot(ddy[0])
    y, dy, ddy = discrete_dmp.rollout(new_goal=np.array([2.]))
    plt.plot(y[0], label='y_scaled')
    plt.title('Discrete DMP')
    plt.legend()
    plt.show()

    # Test Biologically-inspired DMP
    t = np.linspace(0., 1., 100)
    y_d = np.sin(np.pi * t)
    new_goal = np.array([[0.8, -0.25],
                         [0.8, 0.25],
                         [1.2, -0.25]])

    discrete_dmp = DiscreteDMP(num_dmps=2, num_basis=100)
    discrete_dmp.imitate(np.array([t, y_d]))
    y, dy, ddy = discrete_dmp.rollout()
    init_points = np.array([discrete_dmp.y0, discrete_dmp.goal])
    # print(discrete_dmp.generate_goal())
    # print(discrete_dmp.generate_goal(f0=discrete_dmp.f_target[:,0]))

    # check with standard discrete DMP when rescaling the goal
    plt.subplot(1, 3, 1)
    plt.title('Initial discrete DMP')
    plt.scatter(init_points[:,0], init_points[:,1], color='b')
    plt.scatter(new_goal[:, 0], new_goal[:, 1], color='r')
    plt.plot(y[0], y[1], 'b', label='original')

    plt.subplot(1, 3, 2)
    plt.title('Rescaled discrete DMP')
    plt.scatter(init_points[:,0], init_points[:,1], color='b')
    plt.scatter(new_goal[:, 0], new_goal[:, 1], color='r')
    plt.plot(y[0], y[1], 'b', label='original')
    for g in new_goal:
        y, dy, ddy = discrete_dmp.rollout(new_goal=g)
        plt.plot(y[0], y[1], 'g', label='scaled')
    plt.legend(['original', 'scaled'])

    # change goal with biologically-inspired DMP
    new_goal = np.array([[0.8, -0.25],
                         [0.8, 0.25],
                         [0.4, 0.1],
                         [5., 0.15],
                         [1.2, -0.25],
                         [-0.8, 0.1],
                         [-0.8, -0.25],
                         [5., -0.25]])
    bio_dmp = BioDiscreteDMP(num_dmps=2, num_basis=100)
    bio_dmp.imitate(np.array([t, y_d]))
    y, dy, ddy = bio_dmp.rollout()
    init_points = np.array([bio_dmp.y0, bio_dmp.goal])

    plt.subplot(1, 3, 3)
    plt.title('Biologically-inspired DMP')
    plt.scatter(init_points[:, 0], init_points[:, 1], color='b')
    plt.scatter(new_goal[:, 0], new_goal[:, 1], color='r')
    plt.plot(y[0], y[1], 'b', label='original')
    for g in new_goal:
        y, dy, ddy = bio_dmp.rollout(new_goal=g)
        plt.plot(y[0], y[1], 'g', label='scaled')
    plt.legend(['original', 'scaled'])
    plt.show()

    # changing goal at the middle
    y_list = []
    for g in new_goal:
        bio_dmp.reset()
        y_traj = np.zeros((2, 100))
        for t in range(100):
            if t < 30:
                y, dy, ddy = bio_dmp.step()
            else:
                y, dy, ddy = bio_dmp.step(new_goal=g)
            y_traj[:, t] = y
        y_list.append(y_traj)
    for y in y_list:
        plt.plot(y[0], y[1])
    plt.scatter(bio_dmp.y0[0], bio_dmp.y0[1], color='b')
    plt.scatter(new_goal[:, 0], new_goal[:, 1], color='r')
    plt.title('change goal at the middle')
    plt.show()

    # changing goal at the middle but with a moving goal
    g = np.hstack((np.arange(1.0, 2.0, 0.1).reshape(10, -1),
                   np.arange(0.0, 1.0, 0.1).reshape(10, -1)))

    bio_dmp.reset()
    y_traj = np.zeros((2, 100))
    y_list = []
    for t in range(100):
        y, dy, ddy = bio_dmp.step(new_goal=g[int(t/10)])
        y_traj[:, t] = y
        if (t % 10) == 0:
            y_list.append(y)
    y_list = np.array(y_list)

    plt.plot(y_traj[0], y_traj[1])
    plt.scatter(bio_dmp.y0[0], bio_dmp.y0[1], color='b')
    plt.scatter(g[:, 0], g[:, 1], color='r')
    plt.scatter(y_list[:, 0], y_list[:, 1], color='g')
    plt.title('moving goal')
    plt.show()
